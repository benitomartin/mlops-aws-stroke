{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455e6c39",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8fa8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load env variables\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# System Libraries\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Tests\n",
    "import ipytest\n",
    "\n",
    "# Create folders for temporal scripts\n",
    "CODE_FOLDER = Path(\"code_scripts\")\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\"])\n",
    "\n",
    "# Data\n",
    "DATA_FILEPATH = \"../data/clean/clean-stroke-data.csv\"\n",
    "\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "# Change the default logging level form INFO (verbose) to ERROR instead.\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.ERROR)\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07453632",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILEPATH = \"../data/clean/clean-stroke-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a502341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental variables\n",
    "\n",
    "bucket = os.environ[\"BUCKET\"]\n",
    "role = os.environ[\"ROLE\"]\n",
    "\n",
    "COMET_API_KEY = os.environ.get(\"COMET_API_KEY\", None)\n",
    "COMET_PROJECT_NAME = os.environ.get(\"COMET_PROJECT_NAME\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bea83",
   "metadata": {},
   "source": [
    "# Configure Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94dcf81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True for local pipeline and False to run in SageMaker\n",
    "\n",
    "LOCAL_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04c12016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession, PipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=bucket) if not LOCAL_MODE else None\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=bucket),\n",
    "        \"instance_type\": \"local\",\n",
    "        \"image\": None,\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    config = {\n",
    "        \"session\": pipeline_session,\n",
    "        \"instance_type\": \"ml.m5.xlarge\",\n",
    "        \"image\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d33ec2",
   "metadata": {},
   "source": [
    "# Initialize Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd5f2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "S3_LOCATION = f\"s3://{bucket}/stroke\"\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ec70eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the bucket\n",
    "# s3 = boto3.client('s3')\n",
    "# s3.create_bucket(Bucket=bucket,\n",
    "#                  CreateBucketConfiguration={\n",
    "#                      'LocationConstraint': region,})rn\n",
    "\n",
    "# print(f\"Bucket {bucket} created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5de15f",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "57a37156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1    Male  80.0             0              1          Yes        Private   \n",
       "2  Female  49.0             0              0          Yes        Private   \n",
       "3  Female  79.0             1              0          Yes  Self-employed   \n",
       "4    Male  81.0             0              0          Yes        Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban             228.69  36.6  formerly smoked       1  \n",
       "1          Rural             105.92  32.5     never smoked       1  \n",
       "2          Urban             171.23  34.4           smokes       1  \n",
       "3          Rural             174.12  24.0     never smoked       1  \n",
       "4          Urban             186.21  29.0  formerly smoked       1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "clean_df = pd.read_csv(DATA_FILEPATH)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de1c4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload data to bucket \n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "# s3.upload_file(DATA_FILEPATH, bucket, 'stroke/data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339e48c",
   "metadata": {},
   "source": [
    "# Splitting and Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eede68",
   "metadata": {},
   "source": [
    "## Preprocessing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b3f016ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"processing\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.extend([f\"./{CODE_FOLDER}/processing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "841d4a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/processing/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/processing/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def preprocess(base_directory):\n",
    "    \"\"\"\n",
    "    Load, split, and transform the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = _read_data_from_input_csv_files(base_directory)\n",
    "        \n",
    "    X_cat = df.drop(columns = [\"stroke\"]).select_dtypes(include=['object'])\n",
    "    cat_features = X_cat.columns.to_list()\n",
    "\n",
    "    categorical_transformer = make_pipeline(\n",
    "                                    OneHotEncoder())\n",
    "    \n",
    "    features_transformer = ColumnTransformer(\n",
    "                                    transformers=[\n",
    "                                        (\"categorical\", \n",
    "                                        categorical_transformer, \n",
    "                                        cat_features),\n",
    "                                    ],\n",
    "                                    remainder='passthrough')\n",
    "    \n",
    "\n",
    "    \n",
    "    df_train, df_validation, df_test = _split_data(df)\n",
    "    \n",
    "    _save_train_baseline(base_directory, df_train)\n",
    "    _save_test_baseline(base_directory, df_test)\n",
    "\n",
    "    y_test = df_test.pop(\"stroke\").values\n",
    "    y_train = df_train.pop(\"stroke\").values\n",
    "    y_validation = df_validation.pop(\"stroke\").values\n",
    "\n",
    "    X_train = features_transformer.fit_transform(df_train)  \n",
    "    X_validation = features_transformer.transform(df_validation) \n",
    "    X_test = features_transformer.transform(df_test)  \n",
    "\n",
    "    feature_names = features_transformer.get_feature_names_out().tolist()\n",
    "\n",
    "    _save_splits(\n",
    "            base_directory,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_validation,\n",
    "            y_validation,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            feature_names)\n",
    "    \n",
    "    _save_model(base_directory, features_transformer)\n",
    "    \n",
    "\n",
    "def _read_data_from_input_csv_files(base_directory):\n",
    "    \"\"\"\n",
    "    Read the data from the input CSV files.\n",
    "\n",
    "    This function reads every CSV file available and\n",
    "    concatenates them into a single dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_directory = Path(base_directory) / \"input\"\n",
    "    files = list(input_directory.glob(\"*.csv\"))\n",
    "\n",
    "    if len(files) == 0:\n",
    "        message = f\"The are no CSV files in {input_directory.as_posix()}/\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    raw_data = [pd.read_csv(file) for file in files]\n",
    "    df = pd.concat(raw_data)\n",
    "\n",
    "    return df.sample(frac=1, random_state=42)   \n",
    "\n",
    "\n",
    "def _split_data(df):\n",
    "    \"\"\"\n",
    "    Split the data into train, validation, and test.\n",
    "    \"\"\"\n",
    "    \n",
    "    stratify_column = df['stroke']\n",
    "    df_train, temp = train_test_split(df, test_size=0.3, stratify=stratify_column, random_state=42)\n",
    "    df_validation, df_test = train_test_split(temp, test_size=0.5, stratify=temp['stroke'], random_state=42)\n",
    "\n",
    "    return df_train, df_validation, df_test\n",
    "\n",
    "\n",
    "def _save_train_baseline(base_directory, df_train):\n",
    "    \"\"\"\n",
    "    Save the untransformed training data to disk.\n",
    "    Determines the baseline for the model    \n",
    "    \"\"\"\n",
    "    \n",
    "    baseline_path = Path(base_directory) / \"train-baseline\"\n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = df_train.copy()\n",
    "\n",
    "    df = df.drop(\"stroke\", axis=1)\n",
    "\n",
    "    df.to_csv(baseline_path / \"train-baseline.csv\", header=True, index=False)\n",
    "\n",
    "    \n",
    "def _save_test_baseline(base_directory, df_test):\n",
    "    \"\"\"Save the untransformed test data to disk.\n",
    "\n",
    "    We will need the test data to compute a baseline to\n",
    "    determine the quality of the model predictions when deployed.\n",
    "    \"\"\"\n",
    "    \n",
    "    baseline_path = Path(base_directory) / \"test-baseline\"\n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = df_test.copy()\n",
    "\n",
    "    df.to_csv(baseline_path / \"test-baseline.csv\", header=False, index=False)\n",
    "\n",
    "\n",
    "def _save_splits(base_directory,\n",
    "                 X_train,\n",
    "                 y_train,\n",
    "                 X_validation,  \n",
    "                 y_validation,\n",
    "                 X_test,\n",
    "                 y_test,\n",
    "                 feature_names):\n",
    "    \n",
    "    \"\"\"Save data splits to disk.\n",
    "\n",
    "    This function concatenates the transformed features\n",
    "    and the target variable, and saves each one of the split\n",
    "    sets to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, y_validation.reshape(-1, 1)), axis=1)\n",
    "    test = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    train_path = Path(base_directory) / \"train\"\n",
    "    validation_path = Path(base_directory) / \"validation\"\n",
    "    test_path = Path(base_directory) / \"test\"\n",
    "\n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "      \n",
    "    pd.DataFrame(train, columns=feature_names + ['stroke']).to_csv(train_path / \"train.csv\", header=True, index=False)\n",
    "    pd.DataFrame(validation, columns=feature_names + ['stroke']).to_csv(validation_path / \"validation.csv\", header=True, index=False)\n",
    "    pd.DataFrame(test, columns=feature_names + ['stroke']).to_csv(test_path / \"test.csv\", header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "def _save_model(base_directory, features_transformer):\n",
    "    \"\"\"Save the Scikit-Learn transformation pipelines.\n",
    "\n",
    "    This function creates a model.tar.gz file that\n",
    "    contains the two transformation pipelines we built\n",
    "    to transform the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as directory:\n",
    "        joblib.dump(features_transformer, Path(directory) / \"features.joblib\")\n",
    "\n",
    "        model_path = Path(base_directory) / \"model\"\n",
    "        model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with tarfile.open(f\"{(model_path / 'model.tar.gz').as_posix()}\", \"w:gz\") as tar:\n",
    "            tar.add(Path(directory) / \"features.joblib\", arcname=\"features.joblib\",)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(base_directory=\"/opt/ml/processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de180f",
   "metadata": {},
   "source": [
    "## Test Preprocessing Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22f994ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 1.28s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "# | code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "import pytest\n",
    "from code_scripts.processing.script import preprocess\n",
    "\n",
    "\n",
    "@pytest.fixture(autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "\n",
    "    directory = Path(directory)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "        preprocess(base_directory=directory)\n",
    "\n",
    "    yield directory\n",
    "\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "def test_preprocess_directories(directory):\n",
    "    assert (directory / \"train\").exists()\n",
    "    assert (directory / \"test\").exists()\n",
    "    assert (directory / \"train-baseline\").exists()\n",
    "    assert (directory / \"test-baseline\").exists()\n",
    "    assert (directory / \"model\" / \"model.tar.gz\").exists()\n",
    "    assert (directory / \"train\" / \"train.csv\").stat().st_size > 0\n",
    "    assert (directory / \"test\" / \"test.csv\").stat().st_size > 0\n",
    "    assert (directory / \"train-baseline\" / \"train-baseline.csv\").stat().st_size > 0\n",
    "    assert (directory / \"test-baseline\" / \"test-baseline.csv\").stat().st_size > 0\n",
    "\n",
    "    # Check if the model file is created\n",
    "    assert (directory / \"model\" / \"model.tar.gz\").stat().st_size > 0\n",
    "\n",
    "def test_preprocess_generates_data_splits(directory):\n",
    "    output_directories = os.listdir(directory)\n",
    "\n",
    "    assert \"train\" in output_directories\n",
    "    assert \"validation\" in output_directories\n",
    "    assert \"test\" in output_directories\n",
    "\n",
    "\n",
    "def test_splits_are_transformed(directory):\n",
    "    train = pd.read_csv(directory / \"train\" / \"train.csv\", header=None)\n",
    "    validation = pd.read_csv(directory / \"validation\" / \"validation.csv\", header=None)\n",
    "    test = pd.read_csv(directory / \"test\" / \"test.csv\", header=None)\n",
    "\n",
    "    ## After transforming the data, the number of features should be 20:\n",
    "    \n",
    "    # * 2 - gender (one-hot encoded)\n",
    "    # * 1 - age\n",
    "    # * 1 - hypertension\n",
    "    # * 1 - heart_disease\n",
    "    # * 2 - ever_married (one-hot encoded)\n",
    "    # * 5 - work_type (one-hot encoded)\n",
    "    # * 2 - Residence_type (one-hot encoded)\n",
    "    # * 1 - avg_glucose_level\n",
    "    # * 1 - bmi\n",
    "    # * 4 - smoking_status (one-hot encoded)\n",
    "\n",
    "    number_of_features = 20\n",
    "\n",
    "    # The transformed splits should have an additional column for the target variable.\n",
    "    assert train.shape[1] == number_of_features + 1\n",
    "    assert validation.shape[1] == number_of_features + 1\n",
    "    assert test.shape[1] == number_of_features + 1\n",
    "\n",
    "\n",
    "def test_train_baseline_is_not_transformed(directory):\n",
    "    baseline = pd.read_csv(\n",
    "                    directory / \"train-baseline\" / \"train-baseline.csv\",\n",
    "                    header=None)\n",
    "    \n",
    "    gender = baseline.iloc[:, 0].unique()\n",
    "\n",
    "    assert \"Male\" in gender\n",
    "    assert \"Female\" in gender\n",
    "   \n",
    "def test_test_baseline_is_not_transformed(directory):\n",
    "    baseline = pd.read_csv(directory / \"test-baseline\" / \"test-baseline.csv\",\n",
    "                           header=None)\n",
    "     \n",
    "    gender = baseline.iloc[:, 0].unique()\n",
    "\n",
    "    assert \"Male\" in gender\n",
    "    assert \"Female\" in gender\n",
    "\n",
    "def test_train_baseline_includes_header(directory):\n",
    "    baseline = pd.read_csv(directory / \"train-baseline\" / \"train-baseline.csv\")\n",
    "    assert baseline.columns[-1] == \"smoking_status\"\n",
    "\n",
    "def test_test_baseline_does_not_include_header(directory):\n",
    "    baseline = pd.read_csv(directory / \"test-baseline\" / \"test-baseline.csv\")\n",
    "    assert baseline.columns[-1] != \"smoking_status\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab10408",
   "metadata": {},
   "source": [
    "## Caching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1785010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"15d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce98e5b",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "420e23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920118c",
   "metadata": {},
   "source": [
    "## Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b2e3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e58e6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    step_args=processor.run(\n",
    "        code=f\"{(CODE_FOLDER / 'processing' / 'script.py').as_posix()}\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=dataset_location,\n",
    "                destination=\"/opt/ml/processing/input\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\",\n",
    "                source=\"/opt/ml/processing/train\", # Transformed\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\",\n",
    "                source=\"/opt/ml/processing/validation\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/validation\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\",\n",
    "                source=\"/opt/ml/processing/test\", # Transformed\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"model\",\n",
    "                source=\"/opt/ml/processing/model\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/model\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train-baseline\",\n",
    "                source=\"/opt/ml/processing/train-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train-baseline\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test-baseline\",\n",
    "                source=\"/opt/ml/processing/test-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test-baseline\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc65c3",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "907fc596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/preprocessing-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'd41be779-9f32-4521-8206-5b208917ea68',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd41be779-9f32-4521-8206-5b208917ea68',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '93',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    name=\"preprocessing-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"])\n",
    "\n",
    "preprocessing_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "784b958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%script false --no-raise-error\n",
    "# # | eval: false\n",
    "\n",
    "# preprocessing_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead677ed",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cc044",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bfb9252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"training\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.extend([f\"./{CODE_FOLDER}/training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22c54400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/training/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/training/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "from pathlib import Path\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from packaging import version\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score\n",
    "\n",
    "def train(\n",
    "    model_directory,\n",
    "    train_path,\n",
    "    validation_path,\n",
    "    pipeline_path,\n",
    "    experiment,\n",
    "    eta=0.3):\n",
    "    \"\"\"\n",
    "    Train the model, generate metrics, log in comet and save the model\n",
    "    \"\"\"\n",
    "\n",
    "    X_train = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y_train = X_train[X_train.columns[-1]]\n",
    "    X_train = X_train.drop(X_train.columns[-1], axis=1)\n",
    "        \n",
    "    X_validation = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_validation = X_validation[X_validation.columns[-1]]\n",
    "    X_validation = X_validation.drop(X_validation.columns[-1], axis=1)\n",
    "    \n",
    "    \n",
    "    model = xgb.XGBClassifier(objective='binary:logistic', \n",
    "                              eval_metric='auc', \n",
    "                              eta=eta,\n",
    "                              nthread=1)\n",
    "                               \n",
    "    model.fit(X_train, \n",
    "              y_train,\n",
    "              eval_set=[(X_validation, y_validation)],\n",
    "              early_stopping_rounds=10\n",
    "              )\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = model.predict(X_validation)\n",
    "    y_pred_proba = model.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "    # Evaluate the model \n",
    "    roc_auc= roc_auc_score(y_validation, y_pred_proba)\n",
    "    precision = precision_score(y_validation, predictions)\n",
    "    recall = recall_score(y_validation, predictions)\n",
    "    f1 = f1_score(y_validation, predictions)\n",
    "\n",
    "    print(f'auc: {roc_auc}')  \n",
    "    print(f'precision: {precision}')  \n",
    "    print(f'recall: {recall}')  \n",
    "    print(f'f1: {f1}')  \n",
    "\n",
    "    # SAVE MODEL AS BOOSTER\n",
    "    booster = model.get_booster()\n",
    "    model_filepath = Path(model_directory) / \"xgbclass\"\n",
    "    booster.save_model(model_filepath)\n",
    "    # booster.save_model(model_filepath.as_posix())\n",
    "    \n",
    "    # # # SAVE MODEL AS TXT\n",
    "    # model_filepath = Path(model_directory) / \"model.txt\"\n",
    "    # model.save_model(model_filepath)\n",
    "\n",
    "    # # # # SAVE MODEL AS PICKLE\n",
    "    # import pickle\n",
    "    # model_filepath = Path(model_directory) / \"model.pkl\"\n",
    "    # with open(model_filepath, 'wb') as f:\n",
    "    #     # pickle.dump(model.get_booster(), f)        \n",
    "    #     pickle.dump(model, f)\n",
    "\n",
    "\n",
    "  \n",
    "    # Bundle transformation pipelines with model\n",
    "    with tarfile.open(Path(pipeline_path) / \"model.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(model_directory)\n",
    "\n",
    "    if experiment:\n",
    "        experiment.log_parameters(\n",
    "            {\n",
    "                \"eta\": eta,\n",
    "            })\n",
    "\n",
    "        experiment.log_dataset_hash(X_train)\n",
    "        \n",
    "        experiment.log_confusion_matrix(\n",
    "                                y_validation.astype(int), predictions.astype(int))\n",
    "        \n",
    "        experiment.log_model(\"stroke\", model_filepath.as_posix())\n",
    "        experiment.log_metric(\"roc_auc\", roc_auc)\n",
    "        experiment.log_metric(\"precision\", precision)\n",
    "        experiment.log_metric(\"recall\", recall)\n",
    "        experiment.log_metric(\"f1\", f1)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.3)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Create a Comet experiment to log the metrics and parameters\n",
    "    comet_api_key = os.environ.get(\"COMET_API_KEY\", None)\n",
    "    comet_project_name = os.environ.get(\"COMET_PROJECT_NAME\", None)\n",
    "\n",
    "    experiment = (\n",
    "        Experiment(\n",
    "            project_name=comet_project_name,\n",
    "            api_key=comet_api_key,\n",
    "            auto_metric_logging=True,\n",
    "            auto_param_logging=True,\n",
    "            log_code=True,\n",
    "        )\n",
    "        if comet_api_key and comet_project_name\n",
    "        else None)\n",
    "\n",
    "    training_env = json.loads(os.environ.get(\"SM_TRAINING_ENV\", \"{}\"))\n",
    "    job_name = training_env.get(\"job_name\", None) if training_env else None\n",
    "\n",
    "    \n",
    "    # SageMaker's training job name = experiment name\n",
    "    if job_name and experiment:\n",
    "        experiment.set_name(job_name)\n",
    "\n",
    "    # SageMaker will create a model.tar.gz file with anything\n",
    "    # inside this directory when the training script finishes.\n",
    "    # SageMaker creates one channel for each one of the inputs to the Training Step.\n",
    "    train(model_directory=os.environ[\"SM_MODEL_DIR\"], \n",
    "          train_path=os.environ[\"SM_CHANNEL_TRAIN\"],\n",
    "          validation_path=os.environ[\"SM_CHANNEL_VALIDATION\"],\n",
    "          pipeline_path=os.environ[\"SM_CHANNEL_PIPELINE\"],\n",
    "          experiment=experiment,\n",
    "          eta=args.eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05ced4",
   "metadata": {},
   "source": [
    "## Test Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4cc34b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71030\n",
      "[1]\tvalidation_0-auc:0.75081\n",
      "[2]\tvalidation_0-auc:0.73930\n",
      "[3]\tvalidation_0-auc:0.73361\n",
      "[4]\tvalidation_0-auc:0.73631\n",
      "[5]\tvalidation_0-auc:0.74221\n",
      "[6]\tvalidation_0-auc:0.72924\n",
      "[7]\tvalidation_0-auc:0.75003\n",
      "[8]\tvalidation_0-auc:0.75692\n",
      "[9]\tvalidation_0-auc:0.76124\n",
      "[10]\tvalidation_0-auc:0.75854\n",
      "[11]\tvalidation_0-auc:0.75765\n",
      "[12]\tvalidation_0-auc:0.75880\n",
      "[13]\tvalidation_0-auc:0.75436\n",
      "[14]\tvalidation_0-auc:0.75619\n",
      "[15]\tvalidation_0-auc:0.75381\n",
      "[16]\tvalidation_0-auc:0.75331\n",
      "[17]\tvalidation_0-auc:0.75299\n",
      "[18]\tvalidation_0-auc:0.75235\n",
      "auc: 0.7612445664607641\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 80 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:299: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(dtype):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 80 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:301: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 80 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:332: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    if is_categorical_dtype(dtype)\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 80 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:323: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:427: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(data):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\sklearn\\utils\\validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(pd_dtype):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_train_bundles_model_assets\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\sklearn\\utils\\validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m336 warnings\u001b[0m\u001b[33m in 0.34s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pytest\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from code_scripts.processing.script import preprocess\n",
    "from code_scripts.training.script import train\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    # preprocess(base_directory=directory)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "        preprocess(base_directory=directory)\n",
    "                   \n",
    "    train(model_directory=directory / \"model\",\n",
    "          train_path=directory / \"train\", \n",
    "          validation_path=directory / \"validation\",\n",
    "          pipeline_path=directory / \"model\",\n",
    "          experiment=None,\n",
    "          eta=0.3)\n",
    "    \n",
    "    yield directory\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "def test_train_bundles_model_assets(directory):\n",
    "    bundle = os.listdir(directory / \"model\")\n",
    "    assert \"xgbclass\" in bundle\n",
    "    assert \"features.joblib\" in bundle\n",
    "    # assert \"model.txt\" in bundle\n",
    "    # assert \"model.pkl\" in bundle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294421f3",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f3f1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/training/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/training/requirements.txt\n",
    "#| label: requirements.txt\n",
    "#| filename: requirements.txt\n",
    "#| code-line-numbers: false\n",
    "\n",
    "comet_ml\n",
    "urllib3==1.26.5\n",
    "pandas\n",
    "scikit-learn==1.2.1\n",
    "urllib3==1.26.5\n",
    "xgboost==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be5a6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "estimator = XGBoost(base_job_name=\"training\",\n",
    "                    entry_point = \"script.py\", \n",
    "                    framework_version='1.7-1', \n",
    "                    source_dir=f\"{(CODE_FOLDER / 'training').as_posix()}\",\n",
    "                    hyperparameters={\n",
    "                            \"eta\": 0.3,\n",
    "                        },\n",
    "                    environment={\n",
    "                        \"COMET_API_KEY\": COMET_API_KEY,\n",
    "                        \"COMET_PROJECT_NAME\": COMET_PROJECT_NAME,\n",
    "                    },\n",
    "                    # py_version=config[\"py_version\"],\n",
    "                    instance_type=config[\"instance_type\"],\n",
    "                    sagemaker_session=config[\"session\"],\n",
    "               \n",
    "\n",
    "                    role=role,\n",
    "                    instance_count=1\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "afef11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "def create_training_step(estimator):\n",
    "    \"\"\"Create a SageMaker TrainingStep using the provided estimator.\"\"\"\n",
    "    return TrainingStep(\n",
    "        name=\"train-model\",\n",
    "        step_args=estimator.fit(\n",
    "            inputs={\n",
    "                \"train\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"train\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"validation\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"validation\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"pipeline\": TrainingInput(\n",
    "                    s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"model\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"application/tar+gzip\",\n",
    "                ),\n",
    "            },\n",
    "        ),\n",
    "        cache_config=cache_config,\n",
    "    )\n",
    "\n",
    "\n",
    "train_model_step = create_training_step(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1b512",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94cc9533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/training-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '615fb08b-2840-4272-8e38-57688e3d5ad1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '615fb08b-2840-4272-8e38-57688e3d5ad1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '88',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:41 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline = Pipeline(\n",
    "    name=\"training-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        train_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"])\n",
    "\n",
    "training_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d68c3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%script false --no-raise-error\n",
    "# # | eval: false\n",
    "\n",
    "# training_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e2d2b",
   "metadata": {},
   "source": [
    "# Training Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40428402",
   "metadata": {},
   "source": [
    "## Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d25e5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('code_scripts/containers/training/train.py')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "(CODE_FOLDER / \"containers\" / \"training\").mkdir(parents=True, exist_ok=True)\n",
    "shutil.copy2(\n",
    "    CODE_FOLDER / \"training\" / \"script.py\",\n",
    "    CODE_FOLDER / \"containers\" / \"training\" / \"train.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9bce6548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/containers/training/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/containers/training/requirements.txt\n",
    "# | filename: requirements.txt\n",
    "# | code-line-numbers: true\n",
    "\n",
    "sagemaker-training\n",
    "packaging\n",
    "pandas\n",
    "scikit-learn==1.2.1\n",
    "comet_ml\n",
    "urllib3==1.26.5\n",
    "xgboost==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1886c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/containers/training/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/containers/training/Dockerfile\n",
    "# | filename: Dockerfile\n",
    "# | code-line-numbers: true\n",
    "\n",
    "FROM python:3.10-slim\n",
    "\n",
    "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
    "    python3 \\\n",
    "    build-essential libssl-dev pkg-config libhdf5-dev\n",
    "\n",
    "# Let's install the required Python packages from \n",
    "# the requirements.txt file.\n",
    "COPY requirements.txt .\n",
    "RUN pip install --user --upgrade pip\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "# We are going to be running the training script\n",
    "# as the entrypoint of this container.\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "ENV SAGEMAKER_PROGRAM train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5d40f",
   "metadata": {},
   "source": [
    "## Building the Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0593d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_NAME = \"training-container\"\n",
    "\n",
    "# if not LOCAL_MODE:\n",
    "#     # If we aren't running the code in Local Mode, we need\n",
    "#     # to specify we want to build the Docker image for the\n",
    "#     # linux/amd64 architecture before uploading it to ECR.\n",
    "#     print(\"Building Docker image for linux/amd64 architecture...\")\n",
    "\n",
    "#     !docker build --platform=\"linux/amd64\" -t $IMAGE_NAME \\\n",
    "#         $CODE_FOLDER/containers/training/\n",
    "# else:\n",
    "#     # If we are running in Local Mode, we can use the\n",
    "#     # default Docker build command.\n",
    "#     print(\"Building Docker image for arm64 architecture...\")\n",
    "\n",
    "#     !docker build -t $IMAGE_NAME \\\n",
    "#         $CODE_FOLDER/containers/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad60f0f",
   "metadata": {},
   "source": [
    "## Pushing Docker Image to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d283d9",
   "metadata": {},
   "source": [
    "Run in the terminal the following to push the image: \n",
    "\n",
    "./src/image_script.sh \"False\" \"training-container\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93761b3b",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c3d5e4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'730335307143.dkr.ecr.eu-central-1.amazonaws.com/training-container:latest'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_NAME = \"training-container\"\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "tag = \":latest\"\n",
    "\n",
    "training_container_image = (\n",
    "    IMAGE_NAME\n",
    "    if LOCAL_MODE\n",
    "    else (f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{IMAGE_NAME}:latest\")\n",
    ")\n",
    "\n",
    "training_container_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "xgb_docker_estimator = Estimator(\n",
    "    image_uri=training_container_image,\n",
    "    hyperparameters={\n",
    "        \"eta\": 0.3,\n",
    "    },\n",
    "    environment={\n",
    "        \"COMET_API_KEY\": COMET_API_KEY,\n",
    "        \"COMET_PROJECT_NAME\": COMET_PROJECT_NAME,\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "xgb_docker_train_model_step = create_training_step(xgb_docker_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de5c0e",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/training-docker-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '34a74205-cffd-4241-9e66-9ee7b607c15c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '34a74205-cffd-4241-9e66-9ee7b607c15c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '95',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_docker_pipeline = Pipeline(\n",
    "    name=\"training-docker-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        # This time we want to use the new training step\n",
    "        # we created using the custom Docker image.\n",
    "        xgb_docker_train_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "training_docker_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c2c063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%script false --no-raise-error\n",
    "# # | eval: false\n",
    "\n",
    "# training_docker_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0eab1",
   "metadata": {},
   "source": [
    "# Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d117379",
   "metadata": {},
   "source": [
    "##  Tuning Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b8efae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TUNING_STEP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f09f3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_MODE # Local mode must be false to use tuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8d032b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import ContinuousParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name=\"validation:auc\",\n",
    "    objective_type=\"Maximize\",\n",
    "    hyperparameter_ranges={\n",
    "        \"eta\": ContinuousParameter(0.05, 0.5),\n",
    "    },\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"validation:auc\", \n",
    "         \"Regex\": \"auc: ([0-9\\\\.]+)\"\n",
    "        }\n",
    "    ],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "26f43696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "tune_model_step = TuningStep(\n",
    "    name=\"tune-model\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"pipeline\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"model\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"application/tar+gzip\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ac410",
   "metadata": {},
   "source": [
    "## Tuning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e6ea208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/tuning-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'b03fd267-0060-4ac5-bd2b-40b6d41b81c7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b03fd267-0060-4ac5-bd2b-40b6d41b81c7',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_pipeline = Pipeline(\n",
    "    name=\"tuning-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "tuning_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3690d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # %%script false --no-raise-error\n",
    "# # # | eval: false\n",
    "\n",
    "# tuning_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee28935",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89b159",
   "metadata": {},
   "source": [
    "## Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d702b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"evaluation\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30d783f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/evaluation/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation/script.py\n",
    "# | filename: script.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score, f1_score, recall_score, roc_curve \n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    \"\"\"\n",
    "    Model loadin, evaluation and generation of metrics report\n",
    "    \"\"\"\n",
    "        \n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test = X_test.drop(X_test.columns[-1], axis=1)\n",
    "\n",
    "    # Extract the model and load it in memory.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    # # LOAD AS TXT\n",
    "    # model = xgb.XGBClassifier()\n",
    "    # model.load_model(Path(model_path) / \"model.txt\") \n",
    "    # # predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    # predictions = model.predict(X_test)\n",
    "    # # Make predictions for model_logloss\n",
    "    # y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    \n",
    "    # LOAD AS BOOSTER\n",
    "    model_filepath = Path(model_path) / \"xgbclass\"\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(model_filepath)\n",
    "    # booster.set_param(\"nthread\", 1)\n",
    "    # model.load_model(model_filepath.as_posix())\n",
    "    # Make predictions\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_pred_proba = model.predict(dtest)\n",
    "    \n",
    "    # # LOAD AS PICKLE BOOSTER\n",
    "    # import pickle\n",
    "       \n",
    "    # model_filepath = Path(model_path) / \"model.pkl\"\n",
    "    # with open(model_filepath, 'rb') as f:\n",
    "    #     model = xgb.Booster()\n",
    "    #     model = pickle.load(f)\n",
    "        \n",
    "    # dtest = xgb.DMatrix(X_test)\n",
    "    # y_pred_proba = model.predict(dtest)    \n",
    " \n",
    "\n",
    "    # # LOAD AS PICKLE \n",
    "    # import pickle\n",
    "    # model_filepath = Path(model_path) / \"model.pkl\"\n",
    "\n",
    "    # with open(model_filepath, 'rb') as f:\n",
    "    #     model = pickle.load(f)\n",
    "        \n",
    "    # predictions = model.predict(X_test)\n",
    "    # # Make predictions for model_logloss\n",
    "    # y_pred_proba = model.predict_proba(X_test)[:, 1]  \n",
    "    \n",
    "    \n",
    "    # Evaluate the model with the custom threshold\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)     \n",
    "    print(f'auc: {roc_auc}') \n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "    # Find the threshold that gives the best trade-off\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    best_threshold = float(thresholds[optimal_idx])\n",
    "    \n",
    "    # Evaluate the model with the custom threshold\n",
    "    y_pred_custom_threshold = (y_pred_proba >= best_threshold).astype(int)\n",
    "    precision_custom = precision_score(y_test, y_pred_custom_threshold)\n",
    "    recall_custom = recall_score(y_test, y_pred_custom_threshold)\n",
    "    f1_custom = f1_score(y_test, y_pred_custom_threshold)\n",
    "    \n",
    "    # Log in the expected format\n",
    "    print(f'best_threshold: {best_threshold}')  \n",
    "    print(f'auc: {roc_auc}')  \n",
    "    print(f'precision (custom threshold): {precision_custom}')  \n",
    "    print(f'recall (custom threshold): {recall_custom}')  \n",
    "    print(f'f1 (custom threshold): {f1_custom}')  \n",
    "\n",
    "\n",
    "    # Eevaluation report\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"auc\": {\"value\": roc_auc},\n",
    "            \"best_threshold\": {\"value\": best_threshold},\n",
    "            \"precision_custom\": {\"value\": precision_custom},\n",
    "            \"recall_custom\": {\"value\": recall_custom},\n",
    "            \"f1_custom\": {\"value\": f1_custom},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"/opt/ml/processing/model/\",\n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce840af",
   "metadata": {},
   "source": [
    "## Test Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2c5a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71030\n",
      "[1]\tvalidation_0-auc:0.75081\n",
      "[2]\tvalidation_0-auc:0.73930\n",
      "[3]\tvalidation_0-auc:0.73361\n",
      "[4]\tvalidation_0-auc:0.73631\n",
      "[5]\tvalidation_0-auc:0.74221\n",
      "[6]\tvalidation_0-auc:0.72924\n",
      "[7]\tvalidation_0-auc:0.75003\n",
      "[8]\tvalidation_0-auc:0.75692\n",
      "[9]\tvalidation_0-auc:0.76124\n",
      "[10]\tvalidation_0-auc:0.75854\n",
      "[11]\tvalidation_0-auc:0.75765\n",
      "[12]\tvalidation_0-auc:0.75880\n",
      "[13]\tvalidation_0-auc:0.75436\n",
      "[14]\tvalidation_0-auc:0.75619\n",
      "[15]\tvalidation_0-auc:0.75381\n",
      "[16]\tvalidation_0-auc:0.75331\n",
      "[17]\tvalidation_0-auc:0.75299\n",
      "[18]\tvalidation_0-auc:0.75235\n",
      "auc: 0.7612445664607641\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "auc: 0.8607047872340425\n",
      "best_threshold: 0.04540661722421646\n",
      "auc: 0.8607047872340425\n",
      "precision (custom threshold): 0.14432989690721648\n",
      "recall (custom threshold): 0.875\n",
      "f1 (custom threshold): 0.24778761061946902\n",
      "\u001b[32m.\u001b[0m[0]\tvalidation_0-auc:0.71030\n",
      "[1]\tvalidation_0-auc:0.75081\n",
      "[2]\tvalidation_0-auc:0.73930\n",
      "[3]\tvalidation_0-auc:0.73361\n",
      "[4]\tvalidation_0-auc:0.73631\n",
      "[5]\tvalidation_0-auc:0.74221\n",
      "[6]\tvalidation_0-auc:0.72924\n",
      "[7]\tvalidation_0-auc:0.75003\n",
      "[8]\tvalidation_0-auc:0.75692\n",
      "[9]\tvalidation_0-auc:0.76124\n",
      "[10]\tvalidation_0-auc:0.75854\n",
      "[11]\tvalidation_0-auc:0.75765\n",
      "[12]\tvalidation_0-auc:0.75880\n",
      "[13]\tvalidation_0-auc:0.75436\n",
      "[14]\tvalidation_0-auc:0.75619\n",
      "[15]\tvalidation_0-auc:0.75381\n",
      "[16]\tvalidation_0-auc:0.75331\n",
      "[17]\tvalidation_0-auc:0.75299\n",
      "[18]\tvalidation_0-auc:0.75235\n",
      "auc: 0.7612445664607641\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "auc: 0.8607047872340425\n",
      "best_threshold: 0.04540661722421646\n",
      "auc: 0.8607047872340425\n",
      "precision (custom threshold): 0.14432989690721648\n",
      "recall (custom threshold): 0.875\n",
      "f1 (custom threshold): 0.24778761061946902\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 74 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\sklearn\\utils\\validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(pd_dtype):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 74 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\sklearn\\utils\\validation.py:614: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 200 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:299: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(dtype):\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 200 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:301: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 200 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:332: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    if is_categorical_dtype(dtype)\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py: 200 warnings\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:323: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "    return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_evaluate_generates_evaluation_report\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_evaluate_generates_evaluation_report\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_evaluation_report_contains_auc\n",
      "t_4eef12270e334cb2ae7b175e9128d3df.py::test_evaluation_report_contains_auc\n",
      "  c:\\Users\\bmart\\anaconda3\\envs\\str\\lib\\site-packages\\xgboost\\data.py:427: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "    if is_sparse(data):\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m2 passed\u001b[0m, \u001b[33m\u001b[1m952 warnings\u001b[0m\u001b[33m in 0.85s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "# | code-fold: true\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from processing.script import preprocess\n",
    "from training.script import train\n",
    "from evaluation.script import evaluate\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "\n",
    "    directory = Path(directory)\n",
    "\n",
    "    preprocess(base_directory=directory)\n",
    "\n",
    "   \n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        pipeline_path=directory / \"model\",\n",
    "        experiment=None,\n",
    "        eta=0.3\n",
    "    )\n",
    "\n",
    "    # Load the XGBoost model as per Sagemaker requirements\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model/xgbclass\", arcname=\"xgbclass\")\n",
    "        # tar.add(directory / \"model/model.txt\", arcname=\"model.txt\")\n",
    "        # tar.add(directory / \"model/model.pkl\", arcname=\"model.pkl\")\n",
    "\n",
    "\n",
    "    evaluate(\n",
    "        model_path=directory,\n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "\n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_auc(directory):\n",
    "    with open(directory / \"evaluation.json\", \"r\") as file:\n",
    "        report = json.load(file)\n",
    "\n",
    "    assert \"metrics\" in report\n",
    "    assert \"auc\" in report[\"metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e0080",
   "metadata": {},
   "source": [
    "## Get Model Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4a95070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model assets path: {'Std:Join': {'On': '/', 'Values': ['s3:/', 'stroke-bucket', {'Get': 'Steps.tune-model.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}\n"
     ]
    }
   ],
   "source": [
    "model_assets = train_model_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "if USE_TUNING_STEP:\n",
    "    model_assets = tune_model_step.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=config[\"session\"].default_bucket(),\n",
    "    )\n",
    "    \n",
    "print(\"Model assets path:\", model_assets.expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fe1aa",
   "metadata": {},
   "source": [
    "## Save Output Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7e7e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd55d9",
   "metadata": {},
   "source": [
    "##  Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b24eba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost import XGBoostProcessor\n",
    "\n",
    "evaluation_processor = XGBoostProcessor(\n",
    "    base_job_name=\"evaluation-processor\",\n",
    "    framework_version='1.7-1',\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76e32cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_step = ProcessingStep(\n",
    "    name=\"evaluate-model\",\n",
    "    step_args=evaluation_processor.run(\n",
    "        code=f\"{(CODE_FOLDER / 'evaluation' / 'script.py').as_posix()}\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "\n",
    "            ProcessingInput(\n",
    "                source=model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "        ],\n",
    "        \n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\",\n",
    "                source=\"/opt/ml/processing/evaluation\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86176d",
   "metadata": {},
   "source": [
    "##  Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8c8e414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/evaluation-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/evaluation-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/evaluation-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/evaluation-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/evaluation-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'c0842dfa-7cf4-463a-9084-1af428bd2058',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c0842dfa-7cf4-463a-9084-1af428bd2058',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '90',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:51 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_pipeline = Pipeline(\n",
    "    name=\"evaluation-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "evaluation_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b2216cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%script false --no-raise-error\n",
    "# # | eval: false\n",
    "\n",
    "# evaluation_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af337a5",
   "metadata": {},
   "source": [
    "# Registering the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ec767a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_MODEL_PACKAGE_GROUP = \"basic-stroke\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc0a23",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cfcedf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "xgboost_model = XGBoostModel(\n",
    "    model_data=model_assets,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    framework_version=\"1.7-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a981899",
   "metadata": {},
   "source": [
    "## Configuring Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "41e61f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                evaluate_model_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"evaluation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f36d81",
   "metadata": {},
   "source": [
    "## Registering the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "932b5a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "\n",
    "def create_registration_step(\n",
    "    model,\n",
    "    model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    model_metrics=None,\n",
    "    drift_check_baselines=None,\n",
    "):\n",
    "    \"\"\"Create a Registration Step using the supplied parameters.\"\"\"\n",
    "    return ModelStep(\n",
    "        name=\"register\",\n",
    "        step_args=model.register(\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            approval_status=approval_status,\n",
    "            model_metrics=model_metrics,\n",
    "            drift_check_baselines=drift_check_baselines,\n",
    "            content_types=content_types,\n",
    "            response_types=response_types,\n",
    "            inference_instances=[config[\"instance_type\"]],\n",
    "            transform_instances=[config[\"instance_type\"]],\n",
    "            framework_version='1.7-1',\n",
    "            domain=\"MACHINE_LEARNING\",\n",
    "            task=\"CLASSIFICATION\",\n",
    "            # framework=\"XGBOOST\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "register_model_step = create_registration_step(\n",
    "    xgboost_model,\n",
    "    BASIC_MODEL_PACKAGE_GROUP,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a98ba",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/register-model-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/register-model-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/register-model-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/register-model-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/register-model-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '86f83a04-b14e-4ea8-a078-ed19010ec727',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '86f83a04-b14e-4ea8-a078-ed19010ec727',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '94',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "register_model_pipeline = Pipeline(\n",
    "    name=\"register-model-pipeline\",\n",
    "    parameters=[dataset_location],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        register_model_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "register_model_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # %%script false --no-raise-error\n",
    "# # # | eval: false\n",
    "\n",
    "# register_model_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb75e72",
   "metadata": {},
   "source": [
    "# Conditional Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc1ed5",
   "metadata": {},
   "source": [
    "## Accuracy Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "319c031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterFloat\n",
    "\n",
    "# Change the value to the last registered model auc\n",
    "auc_threshold = ParameterFloat(name=\"auc_threshold\", default_value=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39208a",
   "metadata": {},
   "source": [
    "## Fail Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "17db2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \",\n",
    "        values=[\n",
    "            \"Execution failed because the model's auc was lower than\",\n",
    "            auc_threshold,\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465ef7a",
   "metadata": {},
   "source": [
    "## Defining the Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluate_model_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.auc.value\",\n",
    "    ),\n",
    "    right=auc_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62f2d3",
   "metadata": {},
   "source": [
    "## Condition Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-auc\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f64a09",
   "metadata": {},
   "source": [
    "## Conditional Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/conditional-register-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/conditional-register-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/conditional-register-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/conditional-register-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/conditional-register-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '09d62d2f-9cf0-48d1-a31d-39fd3283c554',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '09d62d2f-9cf0-48d1-a31d-39fd3283c554',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '100',\n",
       "   'date': 'Tue, 04 Jun 2024 15:24:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_register_pipeline = Pipeline(\n",
    "    name=\"conditional-register-pipeline\",\n",
    "    parameters=[dataset_location, auc_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "conditional_register_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # %%script false --no-raise-error\n",
    "# # # | eval: false\n",
    "\n",
    "# conditional_register_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3ca3d",
   "metadata": {},
   "source": [
    "# Serving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5f634",
   "metadata": {},
   "source": [
    "## Get Last Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a8b7ae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'basic-stroke',\n",
       " 'ModelPackageVersion': 23,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:eu-central-1:730335307143:model-package/basic-stroke/23',\n",
       " 'CreationTime': datetime.datetime(2024, 6, 4, 17, 2, 46, 588000, tzinfo=tzlocal()),\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelApprovalStatus': 'Approved'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = sagemaker_client.list_model_packages(\n",
    "    ModelPackageGroupName=BASIC_MODEL_PACKAGE_GROUP,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    MaxResults=1,\n",
    ")\n",
    "\n",
    "package = (\n",
    "    response[\"ModelPackageSummaryList\"][0]\n",
    "    if response[\"ModelPackageSummaryList\"]\n",
    "    else None\n",
    ")\n",
    "\n",
    "package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0c35aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"serving\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2495c59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://stroke-bucket/sagemake-8t6nz7mobc9n-xy4c0n1hlV-003-2f36bb35/output/model.tar.gz\n",
      "stroke-bucket\n",
      "Common Identifier: 8t6nz7mobc9n\n",
      "evaluation-pipeline/8t6nz7mobc9n/evaluate-model/output/evaluation/evaluation.json\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "if package:\n",
    "    response = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=package[\"ModelPackageArn\"],\n",
    "    )\n",
    "\n",
    "    model_data = response[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]\n",
    "    print(model_data)\n",
    "    \n",
    "    S3Downloader.download(model_data, (CODE_FOLDER / \"serving\").as_posix())\n",
    "    s3_bucket_name = model_data.split('/')[2]\n",
    "    print(s3_bucket_name)\n",
    "\n",
    "    # Extract the common identifier from the model path\n",
    "    common_identifier = model_data.split('/')[-3].split('-')[1]\n",
    "    print(f'Common Identifier: {common_identifier}')\n",
    "    \n",
    "    s3_key_path = f'evaluation-pipeline/{common_identifier}/evaluate-model/output/evaluation/evaluation.json'\n",
    "    print(s3_key_path)\n",
    "    s3_evaluation_url = f's3://{s3_bucket_name}/{s3_key_path}'\n",
    "    S3Downloader.download(s3_evaluation_url, (CODE_FOLDER / \"serving\").as_posix())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1e391063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMAL_THRESHOLD: 0.019277844578027725\n",
      "AUC: 0.8577570921985815\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch the optimal threshold from S3\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def fetch_auc(bucket, key):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    report = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "    return report['metrics']['auc']['value']\n",
    "\n",
    "AUC = fetch_auc(s3_bucket_name, s3_key_path)\n",
    "\n",
    "def fetch_optimal_threshold(bucket, key):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    report = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "    return report['metrics']['best_threshold']['value']\n",
    "\n",
    "OPTIMAL_THRESHOLD = fetch_optimal_threshold(s3_bucket_name, s3_key_path)\n",
    "\n",
    "print(f\"OPTIMAL_THRESHOLD: {OPTIMAL_THRESHOLD}\")\n",
    "print(f\"AUC: {AUC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dec7bb",
   "metadata": {},
   "source": [
    "## Prediction Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "759e4be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/serving/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/serving/app.py\n",
    "# | filename: app.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import tarfile\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "MODEL_PATH = Path(__file__).parent\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load the optimal threshold from the evaluation report\n",
    "def load_optimal_threshold():\n",
    "    with open(MODEL_PATH / \"evaluation.json\", \"r\") as f:\n",
    "        report = json.load(f)\n",
    "        return report[\"metrics\"][\"best_threshold\"][\"value\"]\n",
    "\n",
    "OPTIMAL_THRESHOLD = load_optimal_threshold()\n",
    "\n",
    "\n",
    "class Model:\n",
    "    model = None\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Extracts the model package and loads the model in memory\n",
    "        if it hasn't been loaded yet.\n",
    "        \"\"\"\n",
    "        # We want to load the model only if it is not loaded yet.\n",
    "        if not Model.model:\n",
    "\n",
    "            # Before we load the model, we need to extract it in\n",
    "            # a temporal directory.\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as directory:\n",
    "                with tarfile.open(MODEL_PATH / \"model.tar.gz\") as tar:\n",
    "                    tar.extractall(path=directory)\n",
    "                \n",
    "                # model_filepath = Path(directory) / \"xgbclass\"\n",
    "                model_filepath = Path(directory) / \"xgbclass\"\n",
    "\n",
    "          \n",
    "                logger.info(f\"Loading model from {model_filepath}\")                  \n",
    "                Model.model = xgb.Booster()\n",
    "                Model.model.load_model(model_filepath)\n",
    "                logger.info(\"Model loaded successfully\")\n",
    "\n",
    "                \n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Generates predictions for the supplied data.\n",
    "        \"\"\"\n",
    "        self.load()\n",
    "        \n",
    "        # Make predictions\n",
    "        dtest = xgb.DMatrix(data)\n",
    "\n",
    "        return Model.model.predict(dtest)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = Model()\n",
    "\n",
    "\n",
    "@app.route(\"/predict/\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.data.decode(\"utf-8\").strip().split('\\n')\n",
    "        features = np.array([row.split(\",\") for row in data]).astype(np.float32)\n",
    "\n",
    "\n",
    "        # Generate probability predictions\n",
    "        predictions_proba = model.predict(features)\n",
    "        \n",
    "        results = []\n",
    "        for prediction_proba in predictions_proba:\n",
    "            # Apply the threshold to get binary predictions\n",
    "            pred_value = int(prediction_proba >= OPTIMAL_THRESHOLD)\n",
    "            confidence = float(prediction_proba)\n",
    "            results.append({\"prediction\": pred_value, \"confidence\": confidence})\n",
    "\n",
    "        return jsonify(results)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f6274",
   "metadata": {},
   "source": [
    "## Getting some predictions\n",
    "\n",
    "$ flask --app src/code_scripts/serving/app.py --debug run --host=0.0.0.0 --port=4242\n",
    "\n",
    "One prediction of 1:\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw '1,0,0,1,0,0,0,1,0,1,0,0,0,1,0,68,1,0,206.09,26.7'\n",
    "```\n",
    "\n",
    "Three prediction of 1:\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw $'1,0,0,1,0,0,0,1,0,1,0,0,0,1,0,68,1,0,206.09,26.7\\n0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,48,0,0,84.2,29.7\\n0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,76,1,0,243.58,33.6'\n",
    "```\n",
    "\n",
    "One prediction of 0:\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw '1,0,1,0,0,0,1,0,0,1,0,1,0,0,0,21,0,0,112.38,25.8'\n",
    "```\n",
    "\n",
    "Three prediction of 0:\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:4242/predict' \\\n",
    "    --header 'Content-Type: text/plain' \\\n",
    "    --data-raw $'1,0,1,0,0,0,1,0,0,1,0,1,0,0,0,21,0,0,112.38,25.8\\n0,1,1,0,0,0,0,0,1,0,1,1,0,0,0,16,0,0,102.3,21.9\\n0,1,1,0,0,0,0,0,1,0,1,1,0,0,0,15,0,0,116.5,27.8'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76bc0c",
   "metadata": {},
   "source": [
    "# Deploying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "83564104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "ENDPOINT = \"model-stroke-endpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa332f0",
   "metadata": {},
   "source": [
    "## Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3876ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:eu-central-1:730335307143:model-package/basic-stroke/23\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "if package:\n",
    "    model_package = ModelPackage(\n",
    "        model_package_arn=package[\"ModelPackageArn\"],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "    print(package[\"ModelPackageArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5db4b4",
   "metadata": {},
   "source": [
    "## Deploying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4b7dac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_package.deploy(\n",
    "#     endpoint_name=ENDPOINT,\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type=config[\"instance_type\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd88c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"\"\"\n",
    "1,0,0,1,0,0,0,1,0,1,0,0,0,1,0,68,1,0,206.09,26.7\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6c13f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# from sagemaker.predictor import Predictor\n",
    "\n",
    "# # Initialize the predictor\n",
    "# predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "\n",
    "# # Define the payload\n",
    "# payload = \"1,0,0,1,0,0,0,1,0,1,0,0,0,1,0,68,1,0,206.09,26.7\"\n",
    "\n",
    "# # Send the payload to the endpoint\n",
    "# response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "\n",
    "# # Assuming the response is a JSON string of probabilities\n",
    "# predictions_proba = json.loads(response.decode('utf-8'))\n",
    "\n",
    "# # Set optimal threshold as in Serving the Model chapter\n",
    "# OPTIMAL_THRESHOLD = OPTIMAL_THRESHOLD\n",
    "\n",
    "# # Apply the threshold to get binary predictions\n",
    "# predictions = []\n",
    "# for prediction_proba in predictions_proba:\n",
    "#     pred_value = int(prediction_proba >= OPTIMAL_THRESHOLD)\n",
    "#     predictions.append(pred_value)\n",
    "\n",
    "# print(f\"Stroke: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2b277c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "\n",
    "# try:\n",
    "#     response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "#     response = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "#     print(json.dumps(response, indent=2))\n",
    "#     print(f\"\\nSpecies: {np.argmax(response['predictions'], axis=1)}\")\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     sagemaker_client.delete_endpoint(EndpointName=ENDPOINT)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd7406c",
   "metadata": {},
   "source": [
    "# Deploying From the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1640d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CAPTURE_PERCENTAGE = 100\n",
    "DATA_CAPTURE_DESTINATION = f\"{S3_LOCATION}/monitoring/data-capture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9dbbaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "(CODE_FOLDER / \"lambda\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2f1d9",
   "metadata": {},
   "source": [
    "## Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "906458f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code_scripts/lambda/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/lambda/lambda.py\n",
    "# | filename: lambda.py\n",
    "# | code-line-numbers: true\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # If we are calling this function from EventBridge,\n",
    "    # we need to extract the model package ARN and the\n",
    "    # approval status from the event details. If we are\n",
    "    # calling this function from the pipeline, we can\n",
    "    # assume the model is approved and we can get the\n",
    "    # model package ARN as a direct parameter.\n",
    "    if \"detail\" in event:\n",
    "        model_package_arn = event[\"detail\"][\"ModelPackageArn\"]\n",
    "        approval_status = event[\"detail\"][\"ModelApprovalStatus\"]\n",
    "    else:\n",
    "        model_package_arn = event[\"model_package_arn\"]\n",
    "        approval_status = \"Approved\"\n",
    "\n",
    "    print(f\"Model: {model_package_arn}\")\n",
    "    print(f\"Approval status: {approval_status}\")\n",
    "\n",
    "    if approval_status != \"Approved\":\n",
    "        response = {\n",
    "            \"message\": \"Skipping deployment.\",\n",
    "            \"approval_status\": approval_status,\n",
    "        }\n",
    "\n",
    "        print(response)\n",
    "        return {\"statusCode\": 200, \"body\": json.dumps(response)}\n",
    "\n",
    "    endpoint_name = os.environ[\"ENDPOINT\"]\n",
    "    data_capture_percentage = int(os.environ[\"DATA_CAPTURE_PERCENTAGE\"])\n",
    "    data_capture_destination = os.environ[\"DATA_CAPTURE_DESTINATION\"]\n",
    "    role = os.environ[\"ROLE\"]\n",
    "\n",
    "    timestamp = time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "    model_name = f\"{endpoint_name}-model-{timestamp}\"\n",
    "    endpoint_config_name = f\"{endpoint_name}-config-{timestamp}\"\n",
    "\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=role,\n",
    "        Containers=[{\"ModelPackageName\": model_package_arn}],\n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        # We can enable Data Capture to record the inputs and outputs\n",
    "        # of the endpoint to use them later for monitoring the model.\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": True,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\"CaptureMode\": \"Input\"},\n",
    "                {\"CaptureMode\": \"Output\"},\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"CsvContentTypes\": [\"text/csv\", \"application/octect-stream\"],\n",
    "                \"JsonContentTypes\": [\"application/json\", \"application/octect-stream\"],\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    response = sagemaker.list_endpoints(NameContains=endpoint_name, MaxResults=1)\n",
    "\n",
    "    if len(response[\"Endpoints\"]) == 0:\n",
    "        # If the endpoint doesn't exist, let's create it.\n",
    "        sagemaker.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name,\n",
    "        )\n",
    "    else:\n",
    "        # If the endpoint already exists, let's update it with the\n",
    "        # new configuration.\n",
    "        sagemaker.update_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name,\n",
    "        )\n",
    "\n",
    "    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint deployed successfully\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "61993526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role \"lambda-deploy-stroke\" already exists with ARN \"arn:aws:iam::730335307143:role/lambda-deploy-stroke\".\n"
     ]
    }
   ],
   "source": [
    "lambda_role_name = \"lambda-deploy-stroke\"\n",
    "lambda_role_arn = None\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=lambda_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"],\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "        Description=\"Lambda Endpoint Deployment\",\n",
    "    )\n",
    "\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    print(f'Role \"{lambda_role_name}\" created with ARN \"{lambda_role_arn}\".')\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    response = iam_client.get_role(RoleName=lambda_role_name)\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "    print(f'Role \"{lambda_role_name}\" already exists with ARN \"{lambda_role_arn}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b99b1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"lambda-depl-stroke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9b3541d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2411feed-1baf-4781-96c1-17b0db3d5903',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 04 Jun 2024 15:25:04 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1619',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '2411feed-1baf-4781-96c1-17b0db3d5903'},\n",
       "  'RetryAttempts': 0},\n",
       " 'FunctionName': 'deployment_function',\n",
       " 'FunctionArn': 'arn:aws:lambda:eu-central-1:730335307143:function:deployment_function',\n",
       " 'Runtime': 'python3.11',\n",
       " 'Role': 'arn:aws:iam::730335307143:role/lambda-deploy-stroke',\n",
       " 'Handler': 'lambda.lambda_handler',\n",
       " 'CodeSize': 3595,\n",
       " 'Description': '',\n",
       " 'Timeout': 600,\n",
       " 'MemorySize': 128,\n",
       " 'LastModified': '2024-06-04T15:25:04.000+0000',\n",
       " 'CodeSha256': 'KXGbRnCljQMzGlLi09xT9dOyewM9JgLXMvtTvTa7sNc=',\n",
       " 'Version': '$LATEST',\n",
       " 'Environment': {'Variables': {'ROLE': 'arn:aws:iam::730335307143:role/service-role/AmazonSageMaker-ExecutionRole-20240511T180225',\n",
       "   'DATA_CAPTURE_PERCENTAGE': '100',\n",
       "   'DATA_CAPTURE_DESTINATION': 's3://stroke-bucket/stroke/monitoring/data-capture',\n",
       "   'ENDPOINT': 'lambda-depl-stroke'}},\n",
       " 'TracingConfig': {'Mode': 'PassThrough'},\n",
       " 'RevisionId': 'fb01b76c-df33-4714-a18e-2b9aadbd66a2',\n",
       " 'Layers': [],\n",
       " 'State': 'Active',\n",
       " 'LastUpdateStatus': 'InProgress',\n",
       " 'LastUpdateStatusReason': 'The function is being created.',\n",
       " 'LastUpdateStatusReasonCode': 'Creating',\n",
       " 'PackageType': 'Zip',\n",
       " 'Architectures': ['x86_64'],\n",
       " 'EphemeralStorage': {'Size': 512},\n",
       " 'SnapStart': {'ApplyOn': 'None', 'OptimizationStatus': 'Off'},\n",
       " 'RuntimeVersionConfig': {'RuntimeVersionArn': 'arn:aws:lambda:eu-central-1::runtime:ebf71d7412c197ac5a7e2577ae2988101405146544334078d5a44c921cca75e7'},\n",
       " 'LoggingConfig': {'LogFormat': 'Text',\n",
       "  'LogGroup': '/aws/lambda/deployment_function'}}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "deploy_lambda_fn = Lambda(\n",
    "    function_name=\"deployment_function\",\n",
    "    execution_role_arn=lambda_role_arn,\n",
    "    script=(CODE_FOLDER / \"lambda\" / \"lambda.py\").as_posix(),\n",
    "    handler=\"lambda.lambda_handler\",\n",
    "    timeout=600,\n",
    "    session=sagemaker_session,\n",
    "    runtime=\"python3.11\",\n",
    "    environment={\n",
    "        \"Variables\": {\n",
    "            \"ENDPOINT\": ENDPOINT,\n",
    "            \"DATA_CAPTURE_DESTINATION\": DATA_CAPTURE_DESTINATION,\n",
    "            \"DATA_CAPTURE_PERCENTAGE\": str(DATA_CAPTURE_PERCENTAGE),\n",
    "            \"ROLE\": role,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "deploy_lambda_fn_response = deploy_lambda_fn.upsert()\n",
    "deploy_lambda_fn_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b531e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "\n",
    "\n",
    "def create_deployment_step(register_model_step):\n",
    "    \"\"\"Create a Deploy Step using the supplied parameters.\"\"\"\n",
    "    return LambdaStep(\n",
    "        name=\"deploy\",\n",
    "        lambda_func=deploy_lambda_fn,\n",
    "        inputs={\n",
    "            \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "deploy_step = create_deployment_step(register_model_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-auc\",\n",
    "    conditions=[condition],\n",
    "    if_steps=[register_model_step, deploy_step],\n",
    "    else_steps=[fail_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "264b2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/lambda-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/lambda-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.processing:Uploaded None to s3://stroke-bucket/lambda-pipeline/code/af7bccc9ab7aa123484460dff61a6567/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://stroke-bucket/lambda-pipeline/code/f3b7867d7495763812a03744135acb08/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-central-1:730335307143:pipeline/lambda-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'f8774ffa-5b39-42c0-ac99-e39d11d709af',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f8774ffa-5b39-42c0-ac99-e39d11d709af',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Tue, 04 Jun 2024 15:25:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_pipeline = Pipeline(\n",
    "    name=\"lambda-pipeline\",\n",
    "    parameters=[dataset_location, auc_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "lambda_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # %%script false --no-raise-error\n",
    "# # # # | eval: false\n",
    "\n",
    "# lambda_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6ae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
